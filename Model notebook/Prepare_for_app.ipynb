{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from google.colab import files\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), \"best_resnet18.pth\")\n",
        "\n",
        "# Download the raw .pth file\n",
        "files.download(\"best_resnet18.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Pe3Mg25XIOHs",
        "outputId": "fc770b9b-a5a5-4f08-d0af-452018a1328c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d799a266-5680-4a1c-94b0-306e7a7cd0bc\", \"best_resnet18.pth\", 45050106)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class IMG_DATA(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.data = df\n",
        "        self.transform = transform or transforms.ToTensor()\n",
        "        self.label_map = {'NONPD': 0, 'PD': 1}\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.data.iloc[index].path\n",
        "        label_str = self.data.iloc[index].label\n",
        "        label = self.label_map[label_str]\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.long), img_path\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "test_dataset  = IMG_DATA(test_df, transform=transform)\n",
        "test_loader   = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "aqroRhnPIeiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# --- Config ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = 2\n",
        "checkpoint_path = \"best_resnet18.pth\"\n",
        "\n",
        "# --- Recreate model and load weights ---\n",
        "model = ResNet18Classifier(num_classes=num_classes, dropout=0.3)\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# --- Label map (same as during training) ---\n",
        "idx2label = {0: \"NONPD\", 1: \"PD\"}\n",
        "\n",
        "# --- Inference on a single image ---\n",
        "def predict_image(img_path: str):\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    tensor = preprocess(img).unsqueeze(0).to(device)  # add batch dim\n",
        "    with torch.no_grad():\n",
        "        logits = model(tensor)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        conf, pred = probs.max(dim=1)\n",
        "    return idx2label[pred.item()], conf.item()\n",
        "\n",
        "# Example:\n",
        "label, confidence = predict_image(\"/content/dataset/PD/PD_SPECTROGRAM_1.png\")\n",
        "print(f\"Predicted: {label} ({confidence*100:.1f}%)\")\n",
        "\n",
        "\n",
        "# --- Inference on a DataLoader (e.g., test_loader) ---\n",
        "def evaluate_loader(loader):\n",
        "    all_preds, all_confs = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Changed to unpack the third item (img_path) as _)\n",
        "        for images, _, _ in loader:\n",
        "            images = images.to(device)\n",
        "            logits = model(images)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            confs, preds = probs.max(dim=1)\n",
        "            all_preds.extend(preds.cpu().tolist())\n",
        "            all_confs.extend(confs.cpu().tolist())\n",
        "    # map back to labels\n",
        "    labels = [idx2label[p] for p in all_preds]\n",
        "    return labels, all_confs\n",
        "\n",
        "# Example with your existing test_loader:\n",
        "labels, confs = evaluate_loader(test_loader)\n",
        "for i, (lbl, conf) in enumerate(zip(labels, confs)):\n",
        "    print(f\"{i:03d}: {lbl} ({conf*100:.1f}%)\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6moUuwnI94X",
        "outputId": "4e002a08-de9d-42c3-fb01-188bba63b5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: PD (99.5%)\n",
            "000: NONPD (99.7%)\n",
            "001: PD (66.6%)\n",
            "002: NONPD (99.2%)\n",
            "003: PD (97.7%)\n",
            "004: PD (99.3%)\n",
            "005: NONPD (97.6%)\n",
            "006: PD (98.9%)\n",
            "007: NONPD (99.2%)\n",
            "008: NONPD (99.7%)\n",
            "009: NONPD (99.2%)\n",
            "010: PD (98.6%)\n",
            "011: PD (97.0%)\n",
            "012: NONPD (99.1%)\n",
            "013: NONPD (99.6%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for images, labels, paths in test_loader:\n",
        "        images = images.to(device)\n",
        "        logits = model(images)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        confs, preds = probs.max(dim=1)\n",
        "\n",
        "        # move back to CPU for printing\n",
        "        preds = preds.cpu().tolist()\n",
        "        confs = confs.cpu().tolist()\n",
        "\n",
        "        for path, p, c in zip(paths, preds, confs):\n",
        "            print(f\"{path} → {idx2label[p]} ({c*100:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOzL7yuYJLXO",
        "outputId": "44209030-13df-4dca-fdca-db8d894f821b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset/NONPD/NONPD_SPECTROGRAM_17.png → NONPD (99.7%)\n",
            "/content/dataset/PD/PD_SPECTROGRAM_39.png → PD (66.6%)\n",
            "/content/dataset/NONPD/NONPD_SPECTROGRAM_31.png → NONPD (99.2%)\n",
            "/content/dataset/PD/PD_SPECTROGRAM_16.png → PD (97.7%)\n",
            "/content/dataset/PD/PD_SPECTROGRAM_35.png → PD (99.3%)\n",
            "/content/dataset/NONPD/NONPD_SPECTROGRAM_29.png → NONPD (97.6%)\n",
            "/content/dataset/PD/PD_SPECTROGRAM_25.png → PD (98.9%)\n",
            "/content/dataset/NONPD/NONPD_SPECTROGRAM_45.png → NONPD (99.2%)\n",
            "/content/dataset/NONPD/NONPD_SPECTROGRAM_27.png → NONPD (99.7%)\n",
            "/content/dataset/NONPD/NONPD_SPECTROGRAM_1.png → NONPD (99.2%)\n",
            "/content/dataset/PD/PD_SPECTROGRAM_13.png → PD (98.6%)\n",
            "/content/dataset/PD/PD_SPECTROGRAM_17.png → PD (97.0%)\n",
            "/content/dataset/NONPD/NONPD_SPECTROGRAM_12.png → NONPD (99.1%)\n",
            "/content/dataset/NONPD/NONPD_SPECTROGRAM_2.png → NONPD (99.6%)\n"
          ]
        }
      ]
    }
  ]
}