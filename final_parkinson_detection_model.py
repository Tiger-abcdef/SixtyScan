# -*- coding: utf-8 -*-
"""Final Parkinson Detection Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19x_Gc59EjCU7NL1738Z9ZjAHxBWJWz5l

## Download Dataset
"""

!gdown https://drive.google.com/uc?id=1Yea6wzjc3ncVmQb-zBmYb03dVEWoR6nG

"""## Preparing Dataset"""

!unzip '/content/current dataset 35 patients.zip' -d dataset

import os
import shutil

base_path = "/content/dataset"

# Loop over all items in the base directory
for item in os.listdir(base_path):
    item_path = os.path.join(base_path, item)

    # Only process directories (e.g., '1-2 non pd', '3-4 pd')
    if os.path.isdir(item_path):
        for subitem in os.listdir(item_path):
            subitem_path = os.path.join(item_path, subitem)

            # Check if the subitem is a 'patient' folder
            if os.path.isdir(subitem_path) and subitem.lower().startswith("patient"):
                target_path = os.path.join(base_path, subitem)

                # Check for conflicts
                if os.path.exists(target_path):
                    print(f"Warning: Target folder {target_path} already exists, skipping!")
                else:
                    # Move the folder
                    shutil.move(subitem_path, target_path)
                    print(f"Moved {subitem_path} → {target_path}")

        # After moving, check if the parent is now empty and remove it
        if not os.listdir(item_path):
            os.rmdir(item_path)
            print(f"Removed empty folder {item_path}")

!rm -rf '/content/dataset/3-4 non pd'

import os
import shutil

base_path = "/content/dataset"
pd_folder = os.path.join(base_path, "pd")
non_pd_folder = os.path.join(base_path, "non pd")

# Create target folders if they don't exist
os.makedirs(pd_folder, exist_ok=True)
os.makedirs(non_pd_folder, exist_ok=True)

# Loop through all items in /content/dataset
for item in os.listdir(base_path):
    item_path = os.path.join(base_path, item)

    # Only process folders starting with 'patient'
    if os.path.isdir(item_path) and item.lower().startswith("patient"):
        # Decide target based on name
        if "non pd" in item.lower():
            target = non_pd_folder
        elif "pd" in item.lower():
            target = pd_folder
        else:
            print(f"Skipping {item_path}: unclear category")
            continue

        target_path = os.path.join(target, item)
        shutil.move(item_path, target_path)
        print(f"Moved {item_path} → {target_path}")

"""## EDA (Exploratory Data Analysis)"""

# อันนี้น้องอาจจะแยก notebook ไปสำหรับ EDA โดยเฉพาะโค้ดจะ clean กว่า

"""## preprocessing

#### concat voice inside each record folder, then convert to spectrogram image
"""

!pip install praat-parselmouth --quiet

import os
import librosa
import numpy as np
import matplotlib
matplotlib.use('Agg')  # disable interactive backend
import matplotlib.pyplot as plt
import librosa.display
from multiprocessing import Pool, cpu_count
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
audio_exts = ('.wav', '.m4a', '.aac')

def process_record(args):
    patient_folder, record_folder, input_folder, output_folder = args

    record_path = os.path.join(input_folder, patient_folder, record_folder)
    voice_files = [f for f in os.listdir(record_path) if f.lower().endswith(audio_exts)]
    if len(voice_files) == 0:
        return f"Skipped (no audio): {record_path}"

    concatenated_audio = []
    sr = None # Initialize sr to None

    for voice_file in voice_files:
        audio_path = os.path.join(record_path, voice_file)
        try:
            audio, current_sr = librosa.load(audio_path, sr=None)
            # Ensure all files have the same sampling rate for concatenation
            if sr is None:
                sr = current_sr
            elif sr != current_sr:
                return f"Skipped (inconsistent sampling rates): {record_path}"
            concatenated_audio.append(audio)
        except Exception as e:
            return f"Failed to load {audio_path}: {e}"

    if not concatenated_audio or sr is None or sr <= 0: # Added check for sr being positive
        return f"Skipped (no valid audio or sampling rate): {record_path}"

    concatenated_audio = np.concatenate(concatenated_audio)

    import parselmouth
    # Pass sampling_frequency as a keyword argument as expected by the constructor
    try:
        snd = parselmouth.Sound(concatenated_audio, sampling_frequency=sr)
    except Exception as e:
         return f"Failed to create parselmouth.Sound for {record_path}: {e}"

    # Continue with feature extraction and spectrogram generation
    pitch = snd.to_pitch()
    intensity = snd.to_intensity()
    formant = snd.to_formant_burg()

    mel_spec = librosa.feature.melspectrogram(y=concatenated_audio, sr=sr)
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)

    output_path = os.path.join(output_folder, patient_folder, record_folder)
    os.makedirs(output_path, exist_ok=True)

    img_path = os.path.join(output_path, 'spectrogram.png')
    plt.figure(figsize=(10, 4))
    plt.axis('off')
    librosa.display.specshow(mel_spec_db, sr=sr, x_axis='time', y_axis='mel')
    plt.tight_layout(pad=0)
    plt.savefig(img_path, bbox_inches='tight', pad_inches=0)
    plt.close()

    return f"Saved: {img_path}"


def concat_and_convert_parallel(input_folder, output_folder):
    tasks = []

    for patient_folder in os.listdir(input_folder):
        patient_path = os.path.join(input_folder, patient_folder)
        if not os.path.isdir(patient_path):
            continue

        for record_folder in os.listdir(patient_path):
            record_path = os.path.join(patient_path, record_folder)
            if not os.path.isdir(record_path):
                continue

            tasks.append((patient_folder, record_folder, input_folder, output_folder))

    print(f"Processing {len(tasks)} record folders using {cpu_count()} CPU cores...")

    with Pool(processes=cpu_count()) as pool:
        # Use imap_unordered for potential performance benefits and to see results as they complete
        for r in tqdm(pool.imap_unordered(process_record, tasks), total=len(tasks), desc=f"Processing {os.path.basename(input_folder)}"):
            print(r)

# Run for both folders
concat_and_convert_parallel("/content/dataset/non pd", "/content/dataset/NONPD")
concat_and_convert_parallel("/content/dataset/pd", "/content/dataset/PD")

"""### Rename img and move to Class folder"""

!rm -rf '/content/dataset/non pd'
!rm -rf '/content/dataset/pd'

import os

def rename_spectrograms(output_folder):
    class_counters = {'NONPD': 1, 'PD': 1}

    for class_folder in ['NONPD', 'PD']:
        class_path = os.path.join(output_folder, class_folder)
        if not os.path.isdir(class_path):
            print(f"Skipping missing folder: {class_path}")
            continue

        # Explicit check, avoid substring errors
        if class_folder.upper() == 'NONPD':
            class_label = 'NONPD'
        elif class_folder.upper() == 'PD':
            class_label = 'PD'
        else:
            continue  # skip any unexpected folders

        for patient_folder in os.listdir(class_path):
            patient_path = os.path.join(class_path, patient_folder)
            if not os.path.isdir(patient_path):
                continue

            for record_folder in os.listdir(patient_path):
                record_path = os.path.join(patient_path, record_folder)
                if not os.path.isdir(record_path):
                    continue

                # Look for any PNG files (ignore their original names)
                for file in os.listdir(record_path):
                    file_path = os.path.join(record_path, file)
                    if os.path.isfile(file_path) and file.lower().endswith('.png'):
                        new_name = f"{class_label}_SPECTROGRAM_{class_counters[class_label]}.png"
                        new_path = os.path.join(record_path, new_name)

                        os.rename(file_path, new_path)
                        print(f"Renamed: {file_path} → {new_path}")

                        class_counters[class_label] += 1

rename_spectrograms("/content/dataset")

"""#### Remove to class folder, and clear unuse cashe"""

!mv /content/dataset/NONPD/*/*/* /content/dataset/NONPD
!mv /content/dataset/PD/*/*/* /content/dataset/PD

import os
import shutil

parent_folders = ["/content/dataset/NONPD", "/content/dataset/PD"]

for parent_folder in parent_folders:
    for item in os.listdir(parent_folder):
        item_path = os.path.join(parent_folder, item)
        if os.path.isdir(item_path):
            shutil.rmtree(item_path)
            print(f"Deleted folder: {item_path}")

"""## Create DataFrame"""

import pandas as pd

# Get file paths using shell
paths = !find /content/dataset/*/* -type f

# Prepare list for dataframe
data = []

for p in paths:
    if 'NONPD' in p:
        label = 'NONPD'
    elif 'PD' in p:
        label = 'PD'
    else:
        print("ALERT")

    data.append({'path': p, 'label': label})

# Build dataframe
dataset = pd.DataFrame(data, columns=['path', 'label'])

"""## Split"""

from sklearn.model_selection import train_test_split

# Split 70% train, 15% val, 15% test
train_df, temp_df = train_test_split(dataset, test_size=0.30, random_state=42, stratify=dataset['label'])
val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'])

"""## Modeling"""

from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import torch

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

from torchvision import transforms

class IMG_DATA(Dataset):
    def __init__(self, df, transform=None):
        self.data = df
        # Always include ToTensor()
        if transform is None:
            self.transform = transforms.ToTensor()
        else:
            self.transform = transform
        self.label_map = {'NONPD': 0, 'PD': 1}

    def __getitem__(self, index):
        img_path = self.data.iloc[index].path
        label_str = self.data.iloc[index].label
        label = self.label_map[label_str]

        image = Image.open(img_path).convert('RGB')
        image = self.transform(image)

        return image, torch.tensor(label)

    def __len__(self):
        return len(self.data)
train_dataset = IMG_DATA(train_df, transform=transform)
test_dataset = IMG_DATA(test_df, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)

"""## Modeling"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models

import torch
import torch.nn as nn
from torchvision import models

class ResNetSpectrogramClassifier(nn.Module):
    def __init__(self, num_classes=2):
        super(ResNetSpectrogramClassifier, self).__init__()

        # Load pretrained ResNet18 backbone
        self.backbone = models.resnet18(pretrained=True)

        # Adapt input layer if needed (spectrograms can be 1-channel or 3-channel)
        if self.backbone.conv1.in_channels != 3:
            self.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)

        # Freeze backbone if you want
        for param in self.backbone.parameters():
            param.requires_grad = False

        # Replace the fully connected (fc) layer
        in_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Sequential(
            nn.Linear(in_features, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.backbone(x)

# Initialize model
model = ResNetSpectrogramClassifier(num_classes=2)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Define loss and optimizer (only the classifier head will be updated)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.backbone.fc.parameters(), lr=1e-4, weight_decay=1e-5)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import random_split, DataLoader

# Assuming model, criterion, optimizer, train_dataset are already defined

# Config
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
epochs = 100
batch_size = 4
patience = 3  # early stopping patience

# Split dataset
val_size = int(0.2 * len(train_dataset))
train_size = len(train_dataset) - val_size
train_data, val_data = random_split(train_dataset, [train_size, val_size])

train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)

# Move model to device
model.to(device)

# Early stopping variables
best_val_loss = float('inf')
patience_counter = 0

for epoch in range(epochs):
    model.train()
    running_loss = 0.0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)

    epoch_loss = running_loss / len(train_loader.dataset)

    # Validation
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * images.size(0)

            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    val_loss /= len(val_loader.dataset)
    val_acc = correct / total

    print(f"Epoch [{epoch+1}/{epochs}] - "
          f"Train Loss: {epoch_loss:.4f} - "
          f"Val Loss: {val_loss:.4f} - "
          f"Val Acc: {val_acc:.4f}")

    # Early stopping check
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        patience_counter = 0
        torch.save(model.state_dict(), "best_model.pth")
        print("Saved new best model")
    else:
        patience_counter += 1
        if patience_counter >= patience:
            print("Early stopping triggered")
            break

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

# --- Evaluate on Validation Set ---
model.eval()
val_preds, val_labels = [], []

with torch.no_grad():
    for images, labels in val_loader:
        images = images.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)

        val_preds.extend(preds.cpu().numpy())
        val_labels.extend(labels.numpy())

print("Validation Classification Report:")
print(classification_report(val_labels, val_preds))

# Load best model
model.load_state_dict(torch.load("best_model.pth"))
model.eval()

# Collect predictions and true labels
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.numpy())

# Convert to arrays
all_preds = np.array(all_preds)
all_labels = np.array(all_labels)

# Generate classification report
target_names = ['NONPD', 'PD']
print("Test Classification Report:")
print(classification_report(all_labels, all_preds, target_names=target_names))

"""## Evaluate"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Load best model
model.load_state_dict(torch.load("best_model.pth"))
model.eval()

# Collect predictions and true labels
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.numpy())

# Generate confusion matrix
cm = confusion_matrix(all_labels, all_preds)
target_names = ['NONPD', 'PD']

# Plot confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens", xticklabels=target_names, yticklabels=target_names)
plt.title("Confusion Matrix (Test Set)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

import torch
from google.colab import files

# Save the model
torch.save(model.state_dict(), "best_model.pth")

# Download the raw .pth file
files.download("best_model.pth")